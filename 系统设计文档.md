# VAR熔池视频分析系统 - 系统设计文档

## 1. 系统概述

### 1.1 系统目标
实现对VAR（真空自耗电弧重熔）熔池过程的实时视频分析，监测熔池动态参数和异常事件，为工艺优化提供数据支持。

### 1.2 系统架构
系统采用**前后端分离 + 独立AI处理模块**的三层架构：

```
┌─────────────┐      ┌─────────────┐      ┌─────────────────┐
│   前端界面   │ ←──→ │   后端服务   │ ←──→ │ AI核心处理模块  │
│  (Vue3)     │ HTTP │ (Spring)    │ MQ   │   (Flask)      │
└─────────────┘      └─────────────┘      └─────────────────┘
                            │
                            ↓
                     ┌──────────────┐
                     │ PostgreSQL   │
                     │ Redis        │
                     │ RabbitMQ     │
                     └──────────────┘
```

## 2. 技术栈

### 2.1 前端
- **框架**：Vue3 + Nuxt4
- **UI组件库**：Nuxt UI 4
- **主要功能**：
  - 视频上传与播放
  - 实时数据展示（折线图、事件列表）
  - 异常事件标注与回放

### 2.2 后端
- **框架**：Spring Boot 3 + Spring Data JPA
- **数据库**：PostgreSQL（持久化存储）
- **缓存**：Redis（任务状态缓存、热数据缓存）
- **数据库迁移**：Flyway
- **消息队列**：RabbitMQ（与AI模块异步通信）

### 2.3 AI核心处理模块
- **框架**：Flask + PyTorch
- **AI模型**：YOLOv11（目标检测） + ByteTrack（多目标追踪）
- **Conda环境**：pytorch

### 2.4 中间件与部署
- **开发环境**：本地运行前后端，Docker运行中间件
- **生产环境**：Docker Compose一键部署所有服务
- **反向代理**：Nginx（生产环境）

## 3. 核心功能模块

### 3.1 视频处理流程

```
1. 用户上传视频并配置分析参数 (前端)
   ↓
2. 后端接收并存储，创建分析任务，计算超时时间 (Spring Boot)
   ↓
3. 发送任务到MQ队列，包含配置参数 (RabbitMQ)
   ↓
4. AI模块消费任务，逐帧分析 (Flask + YOLOv11 + ByteTrack)
   │ - 应用置信度阈值配置
   │ - 监控处理时间，判断是否超时
   ↓
5. 实时推送分析进度到后端 (通过HTTP回调或MQ)
   ↓
6. 前端轮询或WebSocket获取实时进度，显示超时预警
   ↓
7. 分析完成，结果存入数据库
   │ - 正常完成 → 状态: COMPLETED
   │ - 超时完成 → 状态: COMPLETED_TIMEOUT
   ↓
8. 前端展示分析结果（图表 + 异常事件列表 + 超时提示）

**状态流转**：
PENDING → PREPROCESSING → ANALYZING → COMPLETED/COMPLETED_TIMEOUT
                                   ↓
                                 FAILED（任何阶段都可能失败）
```

### 3.2 检测内容

#### 3.2.1 动态参数（时序数据）
- **熔池闪烁频率**（Hz）：通过亮度变化分析
- **熔池面积**（像素）：熔池区域像素统计
- **熔池周长**（像素）：熔池边缘轮廓长度

**存储方式**：按时间（帧号/时间戳）存储，支持绘制折线图

#### 3.2.2 异常事件检测（基于YOLOv11 + ByteTrack）

**检测类别定义**（推荐方案）：
```yaml
names:
  0: 熔池未到边        # 状态检测（熔化初期）
  1: 粘连物           # 物体检测（追踪生成、移动、脱落）
  2: 锭冠             # 物体检测（追踪脱落过程）
  3: 辉光             # 电弧异常（整个区域高亮）
  4: 边弧（侧弧）      # 电弧异常（边缘局部高亮）
  5: 爬弧             # 电弧异常（表面电弧迹线）
```

**事件推断逻辑**：
1. **粘连物追踪**：
   - 首次检测到 → 记录"电极形成粘连物"事件
   - 轨迹移动并消失 → 记录"粘连物脱落"事件
   - 根据消失位置判断：落入熔池 or 被结晶器捕获

2. **锭冠追踪**：
   - 从结晶器边缘开始运动 → 记录"锭冠脱落"事件
   - 轨迹终点为熔池内部

3. **电弧异常**：
   - 辉光/边弧/爬弧：记录出现的时间段（起始-结束帧）

### 3.3 数据模型设计

#### 核心实体
1. **AnalysisTask（分析任务）**
   - id, video_path, status（状态枚举，见下方）
   - video_duration（秒）, timeout_threshold（秒，根据超时比例计算）
   - is_timeout（布尔值）
   - created_at, started_at, preprocessing_completed_at, completed_at

   **状态枚举**：
   - `PENDING`：待处理
   - `PREPROCESSING`：预处理中（视频解析、帧提取、元数据读取）
   - `ANALYZING`：分析中（AI模型推理、目标检测与追踪）
   - `COMPLETED`：已完成
   - `COMPLETED_TIMEOUT`：已完成（超时）
   - `FAILED`：失败

2. **TaskConfig（任务配置）**
   - task_id, timeout_ratio（如"1:4"）
   - confidence_threshold（默认0.5）, iou_threshold（默认0.45）
   - model_version（如"yolov11n"）

3. **DynamicMetric（动态参数）**
   - task_id, frame_number, timestamp
   - flicker_frequency, pool_area, pool_perimeter

4. **AnomalyEvent（异常事件）**
   - task_id, event_type（枚举）, start_frame, end_frame
   - object_id（ByteTrack追踪ID）, metadata（JSON：位置、轨迹等）

5. **TrackingObject（追踪物体）**
   - task_id, object_id, category（粘连物/锭冠）
   - first_frame, last_frame, trajectory（JSON数组）

## 4. 系统交互流程

### 4.1 任务提交流程
```
前端 POST /api/tasks/upload (multipart/video)
  ↓
后端存储视频文件 → 创建Task记录 → 返回task_id
  ↓
后端发送消息到 RabbitMQ (queue: video_analysis)
  {
    "task_id": "xxx",
    "video_path": "/path/to/video.mp4",
    "callback_url": "http://backend/api/tasks/xxx/callback"
  }
```

### 4.2 AI处理流程
```
Flask消费MQ消息 → 更新状态为PREPROCESSING
  ↓
预处理阶段：
  - 读取视频元数据（分辨率、帧率、总帧数）
  - 验证视频格式和完整性
  - 加载YOLOv11模型到内存
  ↓
更新状态为ANALYZING → 开始逐帧分析
  ↓
逐帧检测 + ByteTrack多目标追踪 → 关联前后帧物体ID
  ↓
每处理N帧（如100帧）→ 发送进度到后端
  POST /api/tasks/{task_id}/progress
  {
    "status": "ANALYZING",
    "progress": 0.45,
    "current_frame": 4500,
    "total_frames": 10000,
    "phase": "analyzing"  // 或 "preprocessing"
  }
  ↓
分析完成 → 汇总结果 → 发送到后端
  POST /api/tasks/{task_id}/result
  {
    "status": "COMPLETED",  // 或 "COMPLETED_TIMEOUT"
    "dynamic_metrics": [...],
    "anomaly_events": [...],
    "tracking_objects": [...]
  }
```

### 4.3 前端展示流程
```
前端轮询 GET /api/tasks/{task_id}/status
  ↓
显示进度条（processing状态）
  ↓
任务完成 → 获取结果 GET /api/tasks/{task_id}/result
  ↓
渲染页面：
  - ECharts折线图（动态参数）
  - 事件时间轴（异常事件）
  - 视频播放器（可跳转到事件发生时刻）
```

## 5. 关键技术设计

### 5.1 超时控制机制

#### 5.1.1 超时时间计算
```
超时阈值 = 视频时长 × 超时比例分子 / 超时比例分母

示例：
- 视频时长: 30分钟 = 1800秒
- 超时比例: 1:4
- 超时阈值: 1800 × 4 / 1 = 7200秒 = 120分钟
```

#### 5.1.2 超时检测策略
1. **任务创建时**：
   - 解析视频文件获取时长
   - 根据配置的超时比例计算超时阈值
   - 存储到数据库 `timeout_threshold` 字段

2. **处理过程中**（AI模块）：
   - 预处理阶段（PREPROCESSING）：不计入超时检测（通常很快）
   - 分析阶段（ANALYZING）：每处理N帧（如100帧）检查一次处理时长
   - 如果 `当前时间 - 分析开始时间 > 超时阈值`，设置超时标志
   - 超时后继续处理，但在进度回调中标注 `is_timeout: true`

3. **任务完成时**：
   - 正常完成：`status = COMPLETED`
   - 超时完成：`status = COMPLETED_TIMEOUT`

#### 5.1.3 超时比例配置
支持灵活配置，常见比例：
- `2:5` - 严格（30分钟视频 → 75分钟处理）
- `1:4` - 适中（30分钟视频 → 120分钟处理）
- `1:8` - 宽松（30分钟视频 → 240分钟处理）

配置方式：
- **全局配置**：通过配置文件设置默认比例
- **任务级配置**：上传视频时指定该任务的超时比例

### 5.2 异步任务处理
- **模式**：生产者-消费者模式
- **队列设计**：
  - `video_analysis_queue`：视频分析任务
  - `result_callback_queue`：结果回调（可选）
- **消息持久化**：保证任务不丢失
- **消息确认机制**：手动ACK，处理失败时重新入队

### 5.3 数据库设计要点
- **Flyway迁移**：所有表结构变更通过迁移脚本管理
- **索引优化**：
  - task_id + frame_number（动态参数查询）
  - task_id + event_type（异常事件筛选）
  - status + created_at（任务列表查询）
- **JSONB字段**：metadata、trajectory等非结构化数据
- **枚举类型**：status使用PostgreSQL枚举类型或CHECK约束

### 5.4 Redis缓存策略
- **任务状态缓存**：`task:{task_id}:status` (TTL: 1小时)
- **实时进度缓存**：`task:{task_id}:progress` (TTL: 1小时)
- **超时预警缓存**：`task:{task_id}:timeout_warning` (TTL: 处理完成时删除)
- **热数据缓存**：最近分析的任务结果 (TTL: 24小时)

### 5.5 AI模型优化

#### 5.5.1 检测配置
- **置信度阈值（confidence_threshold）**：
  - 默认值：0.5
  - 可配置范围：0.1 ~ 0.9
  - 用途：过滤低置信度的检测框
  - 建议：初期可设为0.4增加召回率，后期根据误报率调整

- **IoU阈值（iou_threshold）**：
  - 默认值：0.45
  - 可配置范围：0.3 ~ 0.7
  - 用途：NMS（非极大值抑制）去除重叠框

#### 5.5.2 性能优化
- 必选：**批量推理**：累积N帧后批量送入YOLOv11（利用GPU并行）
- 必选：**模型预热**：服务启动时加载模型到内存
- 可选：**轨迹平滑**：对ByteTrack输出的轨迹进行卡尔曼滤波
- 可选：**自适应批次大小**：根据GPU显存动态调整批次大小

## 6. 部署架构

### 6.1 开发环境
```yaml
services:
  postgres:
    image: postgres:17.6
    ports: ["5432:5432"]

  redis:
    image: redis:8.2.1
    ports: ["6379:6379"]

  rabbitmq:
    image: rabbitmq:4.1.4
    ports: ["5672:5672", "15672:15672"]
```
- 前端：`npm run dev` (http://localhost:3000)
- 后端：IDE运行 (http://localhost:8080)
- AI模块：`conda activate pytorch && python app.py` (http://localhost:5000)

### 6.2 生产环境
```yaml
services:
  frontend:
    build: ./frontend
    depends_on: [backend]

  backend:
    build: ./backend
    depends_on: [postgres, redis, rabbitmq]

  ai-processor:
    build: ./ai-processor
    depends_on: [rabbitmq]
    deploy:
      replicas: 2  # 多实例处理

  nginx:
    image: nginx
    ports: ["80:80"]
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

## 7. 扩展性设计

### 7.1 水平扩展
- 可选：**AI处理模块**：部署多个Flask实例，共享RabbitMQ队列
- 可选：**后端服务**：无状态设计，支持多实例负载均衡

### 7.2 功能扩展
- 必选：导出分析报告（PDF/Excel）
- 可选：支持实时视频流分析（RTSP/RTMP）
- 可选：增加模型版本管理（AB测试不同模型）
- 可选：用户管理与权限控制

## 8. 监控与日志

### 8.1 日志记录
- **后端**：SLF4J + Logback（分级日志：INFO/WARN/ERROR）
- **AI模块**：Python logging（记录每帧处理时间、检测结果）

### 8.2 性能监控
- 可选：任务处理时长统计
- 可选：MQ队列积压监控
- 可选：GPU使用率监控（AI模块）

## 9. 安全性考虑
- 必选：视频文件上传：限制文件大小、格式校验
- 必选：敏感信息加密：数据库密码、Redis密码使用环境变量
- 可选：JWT Token认证

---

**文档版本**：v1.0
**更新日期**：2025-10-01
**维护者**：侯阳洋